from fastapi import FastAPI, Header, UploadFile, File
from fastapi.concurrency import run_in_threadpool
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
import httpx
import base64
# import jwt  # JWT ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ
from dotenv import load_dotenv
# ğŸ”„ ìµœì‹  langchain-openai íŒ¨í‚¤ì§€ ì‚¬ìš©
from langchain_openai import OpenAIEmbeddings  
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.chat_models import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
import openai
import pandas as pd
from pathlib import Path
from typing import List, Optional

# ğŸš« ë¯¸ì™„ì„± ì´ìŠˆ ëª¨ë“ˆ ì£¼ì„ì²˜ë¦¬
# from issues.crawler import crawl_kjcn_article

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
# SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key")  # JWTìš© ì‹œí¬ë¦¿ í‚¤

app = FastAPI()

# CORS ì„¤ì • ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class Question(BaseModel):
    question: str
    user_id: Optional[str] = None  # ê°œì¸í™” ê¸°ëŠ¥ì„ ìœ„í•œ ì‚¬ìš©ì ID

knowledge_base = None

@app.on_event("startup")
def startup_event():
    global knowledge_base
    # âœ… ì§€ì‹ë² ì´ìŠ¤ ë‹¤ì‹œ í™œì„±í™” (ë°ì´í„° ë¬¸ì œ í•´ê²°ë¨)
    print("ğŸš€ ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
    data_dir = Path(__file__).parent.parent / "data"
    files = list(data_dir.glob("*.*"))
    knowledge_base = init_knowledge_base(files)
    print("âœ… ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    # # ğŸš« ì„ì‹œ ë¹„í™œì„±í™” (ë” ì´ìƒ í•„ìš” ì—†ìŒ)
    # print("âš ï¸ ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” ì„ì‹œ ë¹„í™œì„±í™” - ì„œë²„ êµ¬ë™ í…ŒìŠ¤íŠ¸")  
    # knowledge_base = None

def process_large_food_csv(file_path: Path, chunk_size: int = 1000) -> List[str]:
    """ëŒ€ìš©ëŸ‰ ìŒì‹ CSV íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (test_langchain.py ë¡œì§ ì ìš©)"""
    chunks = []
    
    try:
        print(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path.name}")
        
        # ğŸ”„ ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„ (í•œê¸€ CSV íŒŒì¼ ëŒ€ì‘)
        encodings_to_try = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
        chunk_iter = None
        
        for encoding in encodings_to_try:
            try:
                chunk_iter = pd.read_csv(file_path, chunksize=chunk_size, encoding=encoding)
                print(f"  ì„±ê³µí•œ ì¸ì½”ë”©: {encoding}")
                break
            except UnicodeDecodeError:
                print(f"  ì‹¤íŒ¨í•œ ì¸ì½”ë”©: {encoding}")
                continue
        
        if chunk_iter is None:
            print(f"  ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨: {file_path.name}")
            return []
        
        for i, chunk_df in enumerate(chunk_iter):
            # ê° ì²­í¬ë¥¼ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            processed_texts = []
            
            for _, row in chunk_df.iterrows():
                try:
                    # í–‰ì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
                    row_text = convert_nutrition_row_to_text(row, chunk_df.columns)
                    if row_text:
                        processed_texts.append(row_text)
                except Exception as e:
                    continue
            
            # ì²­í¬ë³„ë¡œ í…ìŠ¤íŠ¸ ê²°í•©
            if processed_texts:
                chunk_text = f"=== {file_path.name} ì²­í¬ {i+1} ===\n" + "\n".join(processed_texts)
                chunks.append(chunk_text)
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if i % 5 == 0:
                print(f"  ì²˜ë¦¬ë¨: {i * chunk_size}í–‰")
                
    except Exception as e:
        print(f"ëŒ€ìš©ëŸ‰ CSV ì²˜ë¦¬ ì˜¤ë¥˜ ({file_path.name}): {e}")
        return []
    
    print(f"ì™„ë£Œ: {file_path.name} - {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
    return chunks

def convert_nutrition_row_to_text(row, columns) -> str:
    """ì˜ì–‘ì„±ë¶„ ë°ì´í„° í–‰ì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜"""
    
    # ì»¬ëŸ¼ëª…ì—ì„œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
    food_name = None
    nutrition_info = {}
    
    for col in columns:
        value = row[col]
        if pd.isna(value) or value == '':
            continue
            
        col_lower = str(col).lower()
        
        # ìŒì‹ëª… ì¶”ì¶œ (ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ë‚˜ 'ëª…' í¬í•¨ ì»¬ëŸ¼)
        if food_name is None and ('ëª…' in col or col == columns[0]):
            food_name = str(value)
        
        # ì˜ì–‘ì„±ë¶„ ì¶”ì¶œ
        elif any(keyword in col_lower for keyword in ['ì¹¼ë¡œë¦¬', 'ì—´ëŸ‰', 'kcal']):
            nutrition_info['ì¹¼ë¡œë¦¬'] = value
        elif any(keyword in col_lower for keyword in ['ë‹¨ë°±ì§ˆ', 'protein']):
            nutrition_info['ë‹¨ë°±ì§ˆ'] = value
        elif any(keyword in col_lower for keyword in ['íƒ„ìˆ˜í™”ë¬¼', 'carb']):
            nutrition_info['íƒ„ìˆ˜í™”ë¬¼'] = value
        elif any(keyword in col_lower for keyword in ['ì§€ë°©', 'fat']):
            nutrition_info['ì§€ë°©'] = value
        elif any(keyword in col_lower for keyword in ['ë‚˜íŠ¸ë¥¨', 'sodium']):
            nutrition_info['ë‚˜íŠ¸ë¥¨'] = value
        elif any(keyword in col_lower for keyword in ['ë‹¹ë¥˜', 'ë‹¹ë¶„', 'sugar']):
            nutrition_info['ë‹¹ë¥˜'] = value
        elif any(keyword in col_lower for keyword in ['í¬í™”ì§€ë°©']):
            nutrition_info['í¬í™”ì§€ë°©'] = value
    
    # ìì—°ì–´ ë¬¸ì¥ ìƒì„±
    if not food_name:
        return ""
    
    text_parts = [f"{food_name}"]
    
    if nutrition_info:
        nutrition_parts = []
        for key, value in nutrition_info.items():
            if value and str(value) != 'nan':
                nutrition_parts.append(f"{key} {value}")
        
        if nutrition_parts:
            text_parts.append("ì˜ì–‘ì„±ë¶„: " + ", ".join(nutrition_parts))
    
    return " - ".join(text_parts) + "."

def init_knowledge_base(file_paths: List[str]):
    """ê°œì„ ëœ ì§€ì‹ë² ì´ìŠ¤ ì´ˆê¸°í™” (test_langchain.py ë°©ì‹ ì ìš©)"""
    all_texts = []
    
    for file_path in file_paths:
        file_path = Path(file_path)
        suffix = file_path.suffix.lower()
        file_size = file_path.stat().st_size / (1024 * 1024)  # MB
        
        print(f"íŒŒì¼ ì²˜ë¦¬: {file_path.name} ({file_size:.1f}MB)")
        
        # ğŸš« ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤í‚µ (ì„ë² ë”© API ì œí•œ ëŒ€ì‘)
        if file_size > 10:  # 10MB ì´ìƒ íŒŒì¼ ì œì™¸
            print(f"  âš ï¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤í‚µ: {file_path.name} (ì„ë² ë”© ì²˜ë¦¬ ì œí•œ)")
            continue
        
        if suffix == ".txt":
            # ê¸°ì¡´ í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                all_texts.append(content)
            except Exception as e:
                print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì˜¤ë¥˜: {e}")
                
        elif suffix == ".csv":
            # ğŸ”„ ì†Œìš©ëŸ‰ íŒŒì¼ë§Œ ì²˜ë¦¬ (ì¸ì½”ë”© ê°œì„ )
            try:
                # ğŸ”„ ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
                encodings_to_try = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
                df = None
                
                for encoding in encodings_to_try:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding)
                        print(f"  {file_path.name} ì„±ê³µí•œ ì¸ì½”ë”©: {encoding}")
                        break
                    except UnicodeDecodeError:
                        continue
                
                if df is not None:
                    # ğŸ”„ ë°ì´í„° ìƒ˜í”Œë§ìœ¼ë¡œ í¬ê¸° ì¤„ì´ê¸°
                    if len(df) > 1000:
                        df = df.sample(n=1000, random_state=42)
                        print(f"  âœ‚ï¸ ë°ì´í„° ìƒ˜í”Œë§: {len(df)}í–‰ìœ¼ë¡œ ì¶•ì†Œ")
                    
                    all_texts.append(df.to_string(index=False))
                else:
                    print(f"  {file_path.name} ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"CSV íŒŒì¼ ì˜¤ë¥˜: {e}")
    
    # CharacterTextSplitterë¡œ ìµœì¢… ì²­í¬ ë¶„í•  (ğŸ”„ ì²­í¬ í¬ê¸° ì¦ê°€)
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=3000,  # ğŸ”„ ì¦ê°€: 1500 -> 3000
        chunk_overlap=300   # ğŸ”„ ì¦ê°€: 200 -> 300
    )
    
    final_chunks = []
    for text in all_texts:
        if text:
            text_chunks = text_splitter.split_text(text)
            final_chunks.extend(text_chunks)
    
    print(f"ìµœì¢… ì²­í¬ ìˆ˜: {len(final_chunks)}")
    
    # ğŸ”„ ì²­í¬ ìˆ˜ ì œí•œ (OpenAI API ì œí•œ ëŒ€ì‘)
    if len(final_chunks) > 2000:
        final_chunks = final_chunks[:2000]
        print(f"  âœ‚ï¸ ì²­í¬ ìˆ˜ ì œí•œ: {len(final_chunks)}ê°œë¡œ ì¶•ì†Œ")
    
    # OpenAI Embeddingsë¡œ ë²¡í„°í™” (ğŸ”„ ë°°ì¹˜ í¬ê¸° ì¡°ì •)
    embeddings = OpenAIEmbeddings(
        model="text-embedding-ada-002",
        chunk_size=100  # ğŸ”„ ê¸°ë³¸ê°’(1000)ì—ì„œ 100ìœ¼ë¡œ ì¶•ì†Œ
    )
    return FAISS.from_texts(final_chunks, embeddings)

def detect_command(question: str) -> tuple[bool, str]:
    """ëª…ë ¹ì–´ ê°ì§€ í•¨ìˆ˜"""
    command_mappings = {
        "/ìŒì‹": "food",
        "/ì‹ì‚¬": "meal", 
        "/ì‹ë‹¨": "diet",
        "/ì¹¼ë¡œë¦¬": "calorie_intake",
        "/ì˜¤ëŠ˜ìŒì‹": "today_food",
        "/ì–´ì œìŒì‹": "yesterday_food"
    }
    
    for command, command_type in command_mappings.items():
        if question.strip().startswith(command):
            return True, command_type
    
    return False, ""

def detect_food_question(question: str) -> bool:
    """ìŒì‹/ì¹¼ë¡œë¦¬/ì˜ì–‘ì„±ë¶„ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€ (ìš´ë™ ê´€ë ¨ ì¹¼ë¡œë¦¬ ì œì™¸)"""
    
    # ìš´ë™ ê´€ë ¨ ì¹¼ë¡œë¦¬ í‚¤ì›Œë“œ (ìŒì‹ ì•„ë‹˜)
    exercise_calorie_keywords = [
        "ì¹¼ë¡œë¦¬ íƒœìš°", "ì¹¼ë¡œë¦¬ ì†Œì§„", "ì¹¼ë¡œë¦¬ ì†Œëª¨", "ì¹¼ë¡œë¦¬ íƒœìš¸", 
        "ì¹¼ë¡œë¦¬ ì†Œë¹„", "ìš´ë™", "íƒœìš°ë ¤ë©´", "ì†Œì§„í•˜ë ¤ë©´", "ì†Œëª¨í•˜ë ¤ë©´"
    ]
    
    # ìš´ë™ ê´€ë ¨ì´ë©´ False ë°˜í™˜
    if any(keyword in question for keyword in exercise_calorie_keywords):
        return False
    
    # ìŒì‹ ê´€ë ¨ í‚¤ì›Œë“œ
    food_keywords = [
        "ì˜ì–‘ì„±ë¶„", "ì˜ì–‘ì†Œ", "ë‹¨ë°±ì§ˆ", "íƒ„ìˆ˜í™”ë¬¼", "ì§€ë°©", 
        "ë¹„íƒ€ë¯¼", "ë¯¸ë„¤ë„", "ë‚˜íŠ¸ë¥¨", "ìŒì‹", "ì‹í’ˆ", "ìš”ë¦¬",
        "ë¨¹ìœ¼ë©´", "ì„­ì·¨", "ì˜ì–‘", "ì„±ë¶„", "í¬í•¨", "ë“¤ì–´ìˆ",
        "ë‹¹ë¶„", "ë‹¹ë¥˜", "í•¨ëŸ‰", "ì‹œë¦¬ì–¼", "ê¹€ì¹˜", "ëœì¥", "ë¼ë©´", 
        "ë°¥", "ê³ ê¸°", "ìƒì„ ", "ê³¼ì¼", "ì•¼ì±„", "ìš°ìœ ", "ê³„ë€",
        "ì¹¼ë¡œë¦¬ê°€", "ì¹¼ë¡œë¦¬ëŠ”", "ì¹¼ë¡œë¦¬ í•¨ëŸ‰", "ì¹¼ë¡œë¦¬ ì„­ì·¨"
    ]
    
    return any(keyword in question for keyword in food_keywords)

async def call_external_api(command_type: str, user_id: str = None) -> dict:
    """ì™¸ë¶€ API í˜¸ì¶œ í•¨ìˆ˜"""
    external_api_url = "http://localhost:8000"  # ì‹¤ì œ API URLë¡œ ë³€ê²½
    
    # API ì—”ë“œí¬ì¸íŠ¸ ë§¤í•‘
    endpoint_mapping = {
        "food": "/image",
        "meal": "/meals", 
        "diet": "/diet_records",
        "calorie_intake": "/calorie_summary",
        "today_food": "/today_meals",
        "yesterday_food": "/yesterday_meals"
    }
    
    endpoint = endpoint_mapping.get(command_type, "/image")
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{external_api_url}{endpoint}",
                headers={"Content-Type": "application/json"},
                json={
                    "query": command_type,
                    "user_id": user_id
                },
                timeout=30.0
            )
            response.raise_for_status()
            return response.json()
    except Exception as e:
        print(f"ì™¸ë¶€ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return {"error": "ì™¸ë¶€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

async def get_user_profile(user_id: str = None) -> dict:
    """ì™¸ë¶€ APIì—ì„œ ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ"""
    if not user_id:
        # user_idê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡œí•„ ë°˜í™˜
        return {
            "age": 25,
            "gender": "ì—¬ì„±", 
            "weight": 55
        }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"http://localhost:8001/user/profile/{user_id}",  # ì‚¬ìš©ì í”„ë¡œí•„ API
                timeout=10.0
            )
            response.raise_for_status()
            profile_data = response.json()
            
            # API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
            return {
                "age": profile_data.get("age", 25),
                "gender": profile_data.get("gender", "ì—¬ì„±"),
                "weight": profile_data.get("weight", 55)
            }
    except Exception as e:
        print(f"ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ í”„ë¡œí•„ ë°˜í™˜
        return {
            "age": 25,
            "gender": "ì—¬ì„±", 
            "weight": 55
        }

def extract_user_info(question: str, base_profile: dict) -> dict:
    """ì§ˆë¬¸ì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œí•˜ì—¬ ê¸°ë³¸ í”„ë¡œí•„ì— ë®ì–´ì“°ê¸°"""
    import re
    
    # ê¸°ë³¸ í”„ë¡œí•„ë¡œ ì‹œì‘ (ì™¸ë¶€ APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°)
    user_info = base_profile.copy()
    
    # ì§ˆë¬¸ì—ì„œ ë‹¤ë¥¸ ì •ë³´ê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
    age_match = re.search(r'(\d+)ëŒ€', question)
    if age_match:
        user_info["age"] = age_match.group(1) + "ëŒ€"
    
    # ì„±ë³„ ì¶”ì¶œ
    if "ì—¬ì„±" in question or "ì—¬ì" in question:
        user_info["gender"] = "ì—¬ì„±"
    elif "ë‚¨ì„±" in question or "ë‚¨ì" in question:
        user_info["gender"] = "ë‚¨ì„±"
    
    # ì²´ì¤‘ ì¶”ì¶œ
    weight_match = re.search(r'(\d+)\s*(?:kg|í‚¬ë¡œ|í‚¤ë¡œ)', question)
    if weight_match:
        user_info["weight"] = int(weight_match.group(1))
    
    return user_info

def calculate_exercise_time(target_calories: int, weight_kg: int = 60) -> str:
    """ëª©í‘œ ì¹¼ë¡œë¦¬ì— ë§ëŠ” ì •í™•í•œ ìš´ë™ ì‹œê°„ ê³„ì‚°"""
    
    # exercise_dataset.csv ê¸°ë°˜ ê³„ì‚° (70kg ê¸°ì¤€ ë°ì´í„°ë¥¼ weightë¡œ ì¡°ì •)
    exercises = [
        ("ëŸ¬ë‹(ì¼ë°˜)", 563, "ì¤‘ê°•ë„"),
        ("ëŸ¬ë‹(ë¹ ë¦„)", 950, "ê³ ê°•ë„"), 
        ("ìì „ê±°íƒ€ê¸°", 563, "ì¤‘ê°•ë„"),
        ("ì¤„ë„˜ê¸°(ë³´í†µ)", 704, "ê³ ê°•ë„"),
        ("ì¤„ë„˜ê¸°(ë¹ ë¦„)", 844, "ê³ ê°•ë„"),
        ("ìˆ˜ì˜", 563, "ì¤‘ê°•ë„"),
        ("ì—ì–´ë¡œë¹…", 493, "ì¤‘ê°•ë„"),
        ("ì¡°ê¹…", 422, "ì €ê°•ë„")
    ]
    
    result = []
    for name, cal_per_hour_70kg, intensity in exercises:
        # ì²´ì¤‘ ë³´ì • (70kg ê¸°ì¤€ ë°ì´í„°ë¥¼ ì‚¬ìš©ì ì²´ì¤‘ìœ¼ë¡œ ì¡°ì •)
        adjusted_cal = (cal_per_hour_70kg * weight_kg) / 55
        time_needed = (target_calories / adjusted_cal) * 60  # ë¶„ ë‹¨ìœ„
        
        if time_needed <= 90:  # 90ë¶„ ì´ë‚´ ìš´ë™ë§Œ ì¶”ì²œ
            result.append(f"â€¢ {name} ({intensity}): {time_needed:.0f}ë¶„")
    
    return "\n".join(result[:5])  # ìƒìœ„ 5ê°œë§Œ ì¶”ì²œ

# JWT í† í°ì—ì„œ user_id ì¶”ì¶œ í•¨ìˆ˜ (ì£¼ì„ì²˜ë¦¬)
# def extract_user_id_from_token(authorization: str = None) -> str:
#     """JWT í† í°ì—ì„œ user_id ì¶”ì¶œ"""
#     if not authorization or not authorization.startswith("Bearer "):
#         return None
#     
#     try:
#         token = authorization.split(" ")[1]
#         payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
#         return payload.get("user_id")
#     except Exception as e:
#         print(f"í† í° ë””ì½”ë”© ì˜¤ë¥˜: {e}")
#         return None

@app.post("/ask")
async def ask_question(
    request: Question,
    # authorization: str = Header(None)  # JWT í† í°ìš© (ì£¼ì„ì²˜ë¦¬)
):
    global knowledge_base
    
    # # ğŸš« ì§€ì‹ë² ì´ìŠ¤ê°€ ë¹„í™œì„±í™”ëœ ê²½ìš° ì²˜ë¦¬
    # if knowledge_base is None:
    #     return {
    #         "answer": "âš ï¸ í˜„ì¬ ì§€ì‹ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤...", 
    #         "type": "system_message",
    #         "status": "knowledge_base_disabled"
    #     }
    
    # JWT í† í°ì—ì„œ user_id ì¶”ì¶œ (ì£¼ì„ì²˜ë¦¬)
    # user_id = extract_user_id_from_token(authorization)
    # if not user_id:
    #     user_id = request.user_id  # í† í°ì´ ì—†ìœ¼ë©´ requestì—ì„œ ê°€ì ¸ì˜¤ê¸°
    
    # ì„ì‹œ: requestì—ì„œ user_id ì‚¬ìš© (ê°œë°œìš©)
    user_id = request.user_id or "default_user"
    
    # 1ë‹¨ê³„: ëª…ë ¹ì–´ ê°ì§€
    is_command, command_type = detect_command(request.question)
    
    if is_command:
        # íŠ¸ë™ 2: ê°œì¸í™”ëœ API ê¸°ë°˜ ë‹µë³€ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        print(f"ê°œì¸í™” ëª…ë ¹ì–´ ê°ì§€: {command_type}")
        
        # ì™¸ë¶€ APIì—ì„œ ê°œì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        api_data = await call_external_api(command_type, user_id)
        
        if "error" in api_data:
            return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê°œì¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}
        
        # ê°œì¸í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì¶”í›„ êµ¬í˜„)
        # personalized_prompt = get_personalized_prompt(command_type, api_data, request.question)
        
        # ì„ì‹œ ì‘ë‹µ
        return {
            "answer": "ê°œì¸í™” ê¸°ëŠ¥ì€ ê³§ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤.",
            "type": "personalized",
            "command": command_type
        }
    
    # elif detect_food_question(request.question):
    #     # ï¿½ï¿½ ìŒì‹/ì˜ì–‘ì„±ë¶„ ê¸°ëŠ¥ ì„ì‹œ ë¹„í™œì„±í™” (ë°ì´í„° ì˜¤ë¥˜ë¡œ ì¸í•´)
    #     return {
    #         "answer": "âš ï¸ ìŒì‹/ì˜ì–‘ì„±ë¶„ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì–´ í˜„ì¬ í•´ë‹¹ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë°˜ ìš´ë™ ê´€ë ¨ ì§ˆë¬¸ì€ ê³„ì† ì´ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.", 
    #         "type": "food_disabled",
    #         "status": "food_feature_disabled"
    #     }
        
    #     # # ğŸš« íŠ¸ë™ 3: ìŒì‹/ì˜ì–‘ì„±ë¶„ ê¸°ë°˜ ë‹µë³€ (ì„ì‹œ ì£¼ì„ì²˜ë¦¬)
    #     # print("ìŒì‹/ì˜ì–‘ì„±ë¶„ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬")
    #     # 
    #     # docs = knowledge_base.similarity_search(request.question, k=4)
    #     # base_profile = await get_user_profile(user_id)
    #     # user_info = extract_user_info(request.question, base_profile)
    #     # 
    #     # # ìŒì‹ ì „ìš© í”„ë¡¬í”„íŠ¸
    #     # food_prompt = f"""
    # # You are a personalized nutrition expert and dietitian. Based on the provided data, please give optimized nutritional advice to users in a friendly and warm manner like a close friend.
    # # 
    # # Question: {request.question}
    # # 
    # # User Information:
    # # - Age: {user_info['age']} years old
    # # - Gender: {user_info['gender']}  
    # # - Weight: {user_info['weight']}kg
    # # 
    # # When answering, please MUST include the following:
    # # 1. Accurate nutritional analysis based on the food data
    # # 2. Calorie and macronutrient breakdown (carbs, protein, fat)
    # # 3. Health benefits or concerns about this food
    # # 4. Recommendations considering user's profile (age, gender, weight)
    # # 5. Serving size suggestions or alternatives if needed
    # # 6. Please summarize it in 4 lines or less
    # # 
    # # IMPORTANT: Please respond in Korean language only. All answers must be in Korean.
    # # 
    # # Related nutrition data:
    # # """
    # #         
    # #         llm = ChatOpenAI(
    # #             model="gpt-3.5-turbo", 
    # #             temperature=0.1,
    # #             max_tokens=3000,
    # #         )
    # # 
    # #         context = food_prompt + "\n".join([doc.page_content for doc in docs])
    # #         response = await run_in_threadpool(llm.predict, context)
    # #         
    # #         return {
    # #             "answer": response, 
    # #             "type": "nutrition",
    # #             "sources_count": len(docs),
    # #             "user_info": user_info
    # #         }
    
    else:
        # íŠ¸ë™ 1: ê¸°ì¡´ ì§€ì‹ ë² ì´ìŠ¤ ê¸°ë°˜ ë‹µë³€
        print("ì¼ë°˜ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬")
        print(f"ì‚¬ìš© ì¤‘ì¸ user_id: {user_id}")
        
        docs = knowledge_base.similarity_search(request.question, k=4)
        
        # ğŸ†• ì™¸ë¶€ APIì—ì„œ ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ
        base_profile = await get_user_profile(user_id)
        print(f"ì‚¬ìš©ì ê¸°ë³¸ í”„ë¡œí•„: {base_profile}")
        
        # ğŸ†• ì§ˆë¬¸ì—ì„œ ì¶”ê°€ ì •ë³´ ì¶”ì¶œí•˜ì—¬ í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        user_info = extract_user_info(request.question, base_profile)
        print(f"ìµœì¢… ì‚¬ìš©ì ì •ë³´: {user_info}")
        
        # ìš´ë™ ì „ìš© í”„ë¡¬í”„íŠ¸
        enhanced_prompt = f"""
You are a personalized fitness expert. Based on the provided data, please give optimized answers to users in a friendly and warm manner like a close friend.

Question: {request.question}

User Information:
- Age: {user_info['age']} years old
- Gender: {user_info['gender']}  
- Weight: {user_info['weight']}kg

When answering, please MUST include the following:
1. Accurate calorie calculations considering the user's weight ({user_info['weight']}kg)
2. Specific exercise duration and methods
3. Provide 3-5 exercise options
4. Offer choices by exercise intensity level
5. Please summarize it in 4 lines or less


IMPORTANT: Please respond in Korean language only. All answers must be in Korean.

Related exercise data:
"""
        
        llm = ChatOpenAI(
            model="gpt-3.5-turbo", 
            temperature=0,
            max_tokens=3000,
        )

        # ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë‹µë³€ ìƒì„±
        context = enhanced_prompt + "\n".join([doc.page_content for doc in docs])
        response = await run_in_threadpool(llm.predict, context)
        
        return {
            "answer": response, 
            "type": "general",
            "sources_count": len(docs),
            "user_info": user_info,
            "base_profile_source": "external_api" if user_id != "default_user" else "default",
            # "authenticated": user_id != "default_user"  # JWT í™œì„±í™” ì‹œ ì‚¬ìš©
        }

# JWT í™œì„±í™” ì‹œ ì‚¬ìš©í•  ë¡œê·¸ì¸ ì—”ë“œí¬ì¸íŠ¸ (ì£¼ì„ì²˜ë¦¬)
# @app.post("/login")
# async def login(username: str, password: str):
#     # ì‚¬ìš©ì ì¸ì¦ ë¡œì§
#     if authenticate_user(username, password):  # ì‹¤ì œ ì¸ì¦ í•¨ìˆ˜ êµ¬í˜„ í•„ìš”
#         payload = {
#             "user_id": username,
#             "exp": datetime.utcnow() + timedelta(hours=24)
#         }
#         token = jwt.encode(payload, SECRET_KEY, algorithm="HS256")
#         return {"access_token": token, "token_type": "bearer"}
#     else:
#         raise HTTPException(status_code=401, detail="Invalid credentials")

# ìƒˆë¡œìš´ ì—”ë“œí¬ì¸íŠ¸: ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ ë¦¬ìŠ¤íŠ¸
@app.get("/commands")
async def get_available_commands():
    return {
        "commands": [
            {"command": "/ìŒì‹", "description": "ê°œì¸ ì‹ì‚¬ ê¸°ë¡ ë¶„ì„"},
            {"command": "/ì‹ì‚¬", "description": "ìµœê·¼ ì‹ì‚¬ íŒ¨í„´ ë¶„ì„"}, 
            {"command": "/ì‹ë‹¨", "description": "ì‹ë‹¨ ê¸°ë¡ ì¡°íšŒ"},
            {"command": "/ì¹¼ë¡œë¦¬", "description": "ì¹¼ë¡œë¦¬ ì„­ì·¨ ë¶„ì„"},
            {"command": "/ì˜¤ëŠ˜ìŒì‹", "description": "ì˜¤ëŠ˜ ì„­ì·¨í•œ ìŒì‹ ë¶„ì„"},
            {"command": "/ì–´ì œìŒì‹", "description": "ì–´ì œ ì„­ì·¨í•œ ìŒì‹ ë¶„ì„"}
        ]
    }

# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/health")
async def health_check():
    return {"status": "healthy", "knowledge_base_loaded": knowledge_base is not None}

@app.get("/crawl")
async def crawl(url: str):
    print("STEP 1: received url to crawl:", url)
    # result = await crawl_kjcn_article(url) # ì£¼ì„ ì²˜ë¦¬ëœ ëª¨ë“ˆ ì‚¬ìš© ì‹œ ì˜¤ë¥˜ ë°œìƒ
    print("STEP 2: Finished crawl_kjcn_article, returning result")
    return {"message": "ì›¹ í¬ë¡¤ë§ ê¸°ëŠ¥ì€ í˜„ì¬ ë¯¸ì™„ì„±ë˜ì–´ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

# ğŸ½ï¸ ì´ë¯¸ì§€ ê¸°ë°˜ ìŒì‹ ë¶„ì„ ê¸°ëŠ¥
def encode_image(file: UploadFile):
    """ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©"""
    file.file.seek(0)  # íŒŒì¼ í¬ì¸í„°ë¥¼ ì‹œì‘ìœ¼ë¡œ ì´ë™
    content = file.file.read()
    return base64.b64encode(content).decode("utf-8")

@app.post("/api/food/analyze")
async def analyze_food_image(file: UploadFile = File(...)):
    """ìŒì‹ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ì–‘ì„±ë¶„ ì •ë³´ ì œê³µ"""
    try:
        encoded = encode_image(file)
        
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": """
You are a food image analysis expert with deep knowledge in culinary arts. 
If there are more than two food photos, please add the two values together. 
Please analyze the food image provided below carefully, considering its appearance, ingredients, and regional characteristics.  
Provide the following information:

- Dish name
- exact calories (in kcal)
- carbohydrates in the food(grams)
- protein in the food(grams)
- fat in the food(grams)
- Sodium in this food(grams)
- Dietary fiber in that food(grams)
- Number of foods and total amount (grams)

âš  IMPORTANT: Your response must be written in Korean at the end

Format your response exactly like this:

- ìš”ë¦¬ëª…: (dish name in Korean)
- ì¹¼ë¡œë¦¬: (exact calories in kcal)
- íƒ„ìˆ˜í™”ë¬¼: (carbohydrates in the food(grams))
- ë‹¨ë°±ì§ˆ: (protein in the food(grams))
- ì§€ë°©: (fat in the food(grams))
- ë‚˜íŠ¸ë¥¨: (Sodium in this food(grams))
- ì‹ì´ì„¬ìœ : (Dietary fiber in that food(grams))
- ì´ëŸ‰: (Number of foods and total amount (grams))
"""
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{encoded}"
                        }
                    }
                ]
            }
        ]

        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages,
            max_tokens=300
        )
        
        return {
            "result": response.choices[0].message.content,
            "type": "image_analysis",
            "model": "gpt-4-turbo"
        }
        
    except Exception as e:
        return {"error": f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

@app.get("/")
def root():
    return {
        "status": "FastAPI is running",
        "features": [
            "ìš´ë™ & ì˜ì–‘ ì±—ë´‡ (/ask)",
            "ìŒì‹ ì´ë¯¸ì§€ ë¶„ì„ (/api/food/analyze)",
            "ì›¹ í¬ë¡¤ë§ (/crawl)",
            "ì‹œìŠ¤í…œ ìƒíƒœ (/health)"
        ]
    }

    
